{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "##importing the required libariries##\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import operator\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##importing the data into a pandas data frame##\n",
    "train_DF=pd.read_csv('codetest_train.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5000.000000\n",
       "mean        1.143878\n",
       "std         5.259896\n",
       "min       -26.705570\n",
       "25%        -2.034383\n",
       "50%         1.166835\n",
       "75%         4.439549\n",
       "max        26.347818\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b09e510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##getting the statistics of the target values to get a better underestanding\n",
    "#of the proper learning method##\n",
    "n, bins, patches = plt.hist(train_DF['target'], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "train_DF['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##splitting the data into train/test set to have a set for performance evaluation##\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_DF.iloc[:,1:255], \\\n",
    "                                                    train_DF['target'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##data_refine function will: 1-find the non-numeric columns, 2- fill the NaN \n",
    "#in non-numeric columns with the most used element 3- transform the non-numeric \n",
    "#columns to numeric values using LabelEncoder method from SKLearn, 4- fill the \n",
    "#NaN values in the numeric columns using the mean value of them##\n",
    "def data_refine(train_DF):\n",
    "    #1-find the non-numeric columns#\n",
    "    real_or_str=train_DF.applymap(np.isreal).all(0)\n",
    "    non_num_feature=real_or_str[~real_or_str].keys()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in non_num_feature:\n",
    "        #2- fill the NaN in non-numeric columns with the most used element#\n",
    "        train_DF[col].fillna(train_DF[col].describe().top, inplace=True)\n",
    "        #3- transform the non-numeric columns to numeric values using \n",
    "        #LabelEncoder method from SKLearn#\n",
    "        train_DF[col]=le.fit_transform(train_DF[col])\n",
    "    #4- fill the NaN values in the numeric columns using the mean value of them\n",
    "    train_DF.fillna(train_DF.mean(), inplace=True)\n",
    "    return train_DF\n",
    "\n",
    "X_train_refined=data_refine(X_train)\n",
    "X_test_refined=data_refine(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on the training set is:\n",
      "12.0869268614\n",
      "MSE on the test set is:\n",
      "17.2529650053\n"
     ]
    }
   ],
   "source": [
    "##Using a Support Vector Regressor as our learning technique##\n",
    "clf = svm.SVR(C=1, epsilon=0.2)\n",
    "clf.fit(X_train_refined, y_train)\n",
    "print (\"MSE on the training set is:\\n\"), mean_squared_error(y_train, \\\n",
    "                                        clf.predict(X_train_refined))\n",
    "print (\"MSE on the test set is:\\n\"), mean_squared_error(y_test, \\\n",
    "                                        clf.predict(X_test_refined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on the training set is:\n",
      "2.49144749533\n",
      "MSE on the test set is:\n",
      "15.9314309093\n"
     ]
    }
   ],
   "source": [
    "##Using another learning technique (Random Forrest Regressor) on our data##\n",
    "rfr = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "rfr.fit(X_train_refined, y_train)\n",
    "print (\"MSE on the training set is:\\n\"), mean_squared_error(y_train, \\\n",
    "                                        rfr.predict(X_train_refined))\n",
    "print (\"MSE on the test set is:\\n\"), mean_squared_error(y_test, \\\n",
    "                                    rfr.predict(X_test_refined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, both of these models tend to overfit the training set. Linear Regressors/K Nearest Neighbor/Neural Networks yield the same performance and all tend to overfit as well. We will try two different method to overcome overfitting.**\n",
    "\n",
    "    1- We will try to use PCA to reduce the number of features\n",
    "    2- We will pick Random Forrest Regressor as our model and using the k-fold cross \n",
    "    validation technique fine tune the parameters of the SVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 50 features, 0.281870 of variance is preserved and the MSE on    the test set is 36.695022\n",
      "With 100 features, 0.509171 of variance is preserved and the MSE on    the test set is 36.815525\n",
      "With 150 features, 0.702820 of variance is preserved and the MSE on    the test set is 36.236900\n",
      "With 200 features, 0.866501 of variance is preserved and the MSE on    the test set is 36.795260\n"
     ]
    }
   ],
   "source": [
    "##Trying PCA and reducing the number of features and checking if the \n",
    "#performance on the test set improves##\n",
    "for n in [50,100,150,200]:\n",
    "    pca = PCA(n_components=n)\n",
    "    rfr.fit(pca.fit_transform(X_train_refined),y_train)\n",
    "    print \"With %d features, %f of variance is preserved and the MSE on\\\n",
    "    the test set is %f\"%(n, pca.explained_variance_ratio_.sum(),\\\n",
    "    mean_squared_error(y_test, rfr.predict(pca.fit_transform(X_test_refined)))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that almost all of the columns are containing significant amount of variance/data and even using 200 features we are still losing around 15% of the data. Also the performance of our model doesn't improve by using less features and it still overfit. So, next we try to fine tune the parameters of our RFR model using a 5-fold cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##trying different values for n_estimators parameters (number of trees in the forrest) and evaluating the performance \n",
    "#using a 5-folded cross validation on the training set##\n",
    "est_list=[10,20,50,100,200]\n",
    "score={}\n",
    "for est in est_list:\n",
    "    rfr = RandomForestRegressor(n_estimators=est, random_state=0)\n",
    "    rfr.fit(X_train_refined, y_train)\n",
    "    score[est]=cross_val_score(rfr, X_train_refined, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optimal value of n_estimators=200\n"
     ]
    }
   ],
   "source": [
    "##finding the optimal value of n_estimators##\n",
    "n_est=max(score.iteritems(), key=operator.itemgetter(1))[0]\n",
    "print \"the optimal value of n_estimators=%d\"%(n_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on the training set using optimal value of n_estimators is:\n",
      "1.67265451698\n",
      "score on the test set using optimal value of n_estimators is:\n",
      "13.7596595741\n"
     ]
    }
   ],
   "source": [
    "##Using a Random Forest Regressor with the optimal C and epsilon parameters##\n",
    "rfr = RandomForestRegressor(n_estimators=n_est, random_state=0)\n",
    "rfr.fit(X_train_refined, y_train)\n",
    "print (\"score on the training set using optimal value of n_estimators is:\\n\"),\\\n",
    "mean_squared_error(y_train, rfr.predict(X_train_refined))\n",
    "print (\"score on the test set using optimal value of n_estimators is:\\n\"), \\\n",
    "mean_squared_error(y_test, rfr.predict(X_test_refined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see the performance improvement using a larger number of trees was marginal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##predicting the target on the given test set and writing the output into a text file##\n",
    "final_test_DF=pd.read_csv('codetest_test.txt', delimiter='\\t')\n",
    "X_test_final_refined=data_refine(final_test_DF)\n",
    "predictions=rfr.predict(X_test_final_refined)\n",
    "f = open('predicted_target_test.txt', 'w')\n",
    "for pre in predictions:\n",
    "    f.writelines(str(pre)+'\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
