{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237.53833333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) Compute the average of a list of numbers. use list comprehension.\n",
    "L=[23,32,121,22,1222.23,5]\n",
    "sum(L)/len(L)\n",
    "#[sum(i) for i in set(L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (2) Compute the number of times each word occurs in the following text.\n",
    "# Transform all words to lower case. Output a list of\n",
    "#  word,count pairs, one pair per line sorted from highest to lowest count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 19), ('the', 18), ('of', 16), ('and', 13), ('are', 7), ('their', 7), ('them', 6), ('these', 6), ('that', 6), ('is', 5), ('which', 5), ('a', 5), ('Government', 4), ('it', 4), ('such', 4), ('all', 3), ('they', 3), ('be', 3), ('among', 3), ('powers', 3), ('its', 2), ('should', 2), ('alter', 2), ('right', 2), ('new', 2), ('by', 2), ('usurpations', 2), ('equal', 2), ('Happiness', 2), ('long', 2), ('Governments', 2), ('with', 2), ('history', 2), ('in', 2), ('absolute', 2), ('mankind', 2), ('for', 2), ('That', 2), ('opinions', 1), ('just', 1), ('indeed', 1), ('over', 1), ('hath', 1), ('Systems', 1), ('invariably', 1), ('earth', 1), ('suffer', 1), ('causes', 1), ('We', 1), ('Object', 1), ('forms', 1), ('consent', 1), ('has', 1), ('than', 1), ('bands', 1), ('candid', 1), ('not', 1), ('world', 1), ('now', 1), ('Right', 1), ('rights', 1), ('truths', 1), ('Despotism', 1), ('causes;', 1), ('abolishing', 1), ('established', 1), ('foundation', 1), ('laying', 1), ('reduce', 1), ('instituted', 1), ('Liberty', 1), ('likely', 1), ('shewn', 1), ('organizing', 1), ('impel', 1), ('Life', 1), ('Form', 1), ('Men', 1), ('while', 1), ('injuries', 1), ('unalienable', 1), ('ends', 1), ('patient', 1), ('Rights', 1), ('men', 1), ('separate', 1), ('let', 1), ('pursuit', 1), ('separation', 1), ('constrains', 1), ('on', 1), ('deriving', 1), ('People', 1), ('institute', 1), ('changed', 1), ('experience', 1), ('Facts', 1), ('sufferance', 1), ('or', 1), ('duty', 1), ('secure', 1), ('Safety', 1), ('been', 1), ('another', 1), ('respect', 1), ('from', 1), ('Nature', 1), ('decent', 1), ('sufferable', 1), ('disposed', 1), ('But', 1), ('throw', 1), ('accordingly', 1), ('station', 1), ('entitle', 1), ('certain', 1), ('Such', 1), ('themselves', 1), ('form', 1), ('evinces', 1), ('becomes', 1), ('King', 1), ('under', 1), ('principles', 1), ('repeated', 1), ('transient', 1), ('hold', 1), ('former', 1), ('present', 1), ('Laws', 1), ('evident', 1), ('Creator', 1), ('this', 1), ('created', 1), ('submitted', 1), ('will', 1), ('whenever', 1), ('Britain', 1), ('future', 1), ('accustomed', 1), ('abuses', 1), ('design', 1), ('more', 1), ('declare', 1), ('Colonies;', 1), ('security', 1), ('endowed', 1), ('an', 1), ('direct', 1), ('To', 1), ('as', 1), ('have', 1), ('dictate', 1), ('pursuing', 1), ('seem', 1), ('any', 1), ('evils', 1), ('self', 1), ('Prudence', 1), ('same', 1), ('abolish', 1), ('God', 1), ('when', 1), ('establishment', 1), ('Tyranny', 1), ('Great', 1), ('shall', 1), ('object', 1), ('effect', 1), ('Guards', 1), ('most', 1), ('connected', 1), ('necessity', 1), ('The', 1), ('destructive', 1), ('prove', 1), ('off', 1), ('assume', 1), ('light', 1), ('governed', 1), ('States', 1), ('provide', 1), ('train', 1), (\"Nature's\", 1), ('requires', 1), ('having', 1)]\n"
     ]
    }
   ],
   "source": [
    "Text=\"\"\"\n",
    "bands which have connected them with another, and to assume among the\n",
    "powers of the earth, the separate and equal station to which the Laws\n",
    "of Nature and of Nature's God entitle them, a decent respect to the\n",
    "opinions of mankind requires that they should declare the causes which\n",
    "impel them to the separation.  We hold these truths to be\n",
    "self-evident, that all men are created equal, that they are endowed by\n",
    "their Creator with certain unalienable Rights, that among these are\n",
    "Life, Liberty and the pursuit of Happiness.--That to secure these\n",
    "rights, Governments are instituted among Men, deriving their just\n",
    "powers from the consent of the governed, --That whenever any Form of\n",
    "Government becomes destructive of these ends, it is the Right of the\n",
    "People to alter or to abolish it, and to institute new Government,\n",
    "laying its foundation on such principles and organizing its powers in\n",
    "such form, as to them shall seem most likely to effect their Safety\n",
    "and Happiness. Prudence, indeed, will dictate that Governments long\n",
    "established should not be changed for light and transient causes; and\n",
    "accordingly all experience hath shewn, that mankind are more disposed\n",
    "to suffer, while evils are sufferable, than to right themselves by\n",
    "abolishing the forms to which they are accustomed. But when a long\n",
    "train of abuses and usurpations, pursuing invariably the same Object\n",
    "evinces a design to reduce them under absolute Despotism, it is their\n",
    "right, it is their duty, to throw off such Government, and to provide\n",
    "new Guards for their future security.--Such has been the patient\n",
    "sufferance of these Colonies; and such is now the necessity which\n",
    "constrains them to alter their former Systems of Government. The\n",
    "history of the present King of Great Britain is a history of repeated\n",
    "injuries and usurpations, all having in direct object the\n",
    "establishment of an absolute Tyranny over these States. To prove this,\n",
    "let Facts be submitted to a candid world.\n",
    "\"\"\"\n",
    "import operator\n",
    "# First, we replace the punctuations marks with spaces\n",
    "for char in '-.,\"\\n':\n",
    "    Text=Text.replace(char,' ')\n",
    "    \n",
    "Text.lower()\n",
    "splitted_text = Text.split(' ')\n",
    "while splitted_text.count('')>0: \n",
    "    splitted_text.remove('') \n",
    "\n",
    "result_dict = dict( [ (i, splitted_text.count(i)) for i in set(splitted_text) ] )\n",
    "result_dict_sorted =sorted(result_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print result_dict_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('of', 'the'), 4), (('it', 'is'), 3), (('and', 'to'), 3), (('of', 'these'), 2), (('that', 'they'), 2), (('they', 'are'), 2), (('to', 'the'), 2), (('them', 'to'), 2), (('to', 'which'), 2), (('is', 'their'), 2), (('and', 'usurpations'), 2), (('to', 'alter'), 2), (('of', 'Government'), 2), (('history', 'of'), 2), (('alter', 'their'), 1), (('to', 'assume'), 1), (('form', 'as'), 1), (('Nature', 'and'), 1), (('and', 'the'), 1), (('which', 'have'), 1), (('God', 'entitle'), 1), (('Form', 'of'), 1), (('the', 'separate'), 1), (('Right', 'of'), 1), (('while', 'evils'), 1), (('by', 'abolishing'), 1), (('accustomed', 'But'), 1), (('organizing', 'its'), 1), (('pursuit', 'of'), 1), (('just', 'powers'), 1), (('their', 'Creator'), 1), (('are', 'Life'), 1), (('as', 'to'), 1), (('Government', 'laying'), 1), (('indeed', 'will'), 1), (('their', 'right'), 1), (('a', 'history'), 1), (('Despotism', 'it'), 1), (('laying', 'its'), 1), (('to', 'effect'), 1), (('right', 'themselves'), 1), (('to', 'abolish'), 1), (('design', 'to'), 1), (('suffer', 'while'), 1), (('Government', 'becomes'), 1), (('present', 'King'), 1), (('evident', 'that'), 1), (('the', 'opinions'), 1), (('by', 'their'), 1), (('of', 'mankind'), 1), (('becomes', 'destructive'), 1), (('pursuing', 'invariably'), 1), (('The', 'history'), 1), (('patient', 'sufferance'), 1), (('are', 'more'), 1), (('certain', 'unalienable'), 1), (('these', 'rights'), 1), (('be', 'self'), 1), (('are', 'created'), 1), (('another', 'and'), 1), (('instituted', 'among'), 1), (('now', 'the'), 1), (('these', 'ends'), 1), (('these', 'truths'), 1), (('self', 'evident'), 1), (('a', 'design'), 1), (('with', 'certain'), 1), (('which', 'impel'), 1), (('causes', 'which'), 1), (('Systems', 'of'), 1), (('object', 'the'), 1), (('connected', 'them'), 1), (('opinions', 'of'), 1), (('invariably', 'the'), 1), (('Governments', 'are'), 1), (('Life', 'Liberty'), 1), (('in', 'such'), 1), (('light', 'and'), 1), (('entitle', 'them'), 1), (('Rights', 'that'), 1), (('let', 'Facts'), 1), (('assume', 'among'), 1), (('evils', 'are'), 1), (('their', 'duty'), 1), (('the', 'necessity'), 1), (('an', 'absolute'), 1), (('hath', 'shewn'), 1), (('to', 'them'), 1), (('disposed', 'to'), 1), (('been', 'the'), 1), (('Liberty', 'and'), 1), (('to', 'reduce'), 1), (('and', 'of'), 1), (('constrains', 'them'), 1), (('such', 'is'), 1), (('Guards', 'for'), 1), (('all', 'having'), 1), (('separate', 'and'), 1), (('under', 'absolute'), 1), (('secure', 'these'), 1), (('mankind', 'requires'), 1), (('created', 'equal'), 1), (('all', 'men'), 1), (('and', 'accordingly'), 1), (('will', 'dictate'), 1), (('such', 'principles'), 1), (('declare', 'the'), 1), (('the', 'causes'), 1), (('the', 'establishment'), 1), (('King', 'of'), 1), (('unalienable', 'Rights'), 1), (('these', 'States'), 1), (('Prudence', 'indeed'), 1), (('most', 'likely'), 1), (('hold', 'these'), 1), (('or', 'to'), 1), (('to', 'provide'), 1), (('not', 'be'), 1), (('their', 'just'), 1), (('on', 'such'), 1), (('Government', 'The'), 1), (('necessity', 'which'), 1), (('Object', 'evinces'), 1), (('is', 'the'), 1), (('with', 'another'), 1), (('them', 'a'), 1), (('consent', 'of'), 1), (('earth', 'the'), 1), (('a', 'candid'), 1), (('equal', 'that'), 1), (('abuses', 'and'), 1), (('Tyranny', 'over'), 1), (('Creator', 'with'), 1), (('established', 'should'), 1), (('long', 'established'), 1), (('usurpations', 'all'), 1), (('reduce', 'them'), 1), (('experience', 'hath'), 1), (('be', 'changed'), 1), (('them', 'with'), 1), (('Men', 'deriving'), 1), (('Laws', 'of'), 1), (('their', 'former'), 1), (('to', 'a'), 1), (('such', 'form'), 1), (('such', 'Government'), 1), (('from', 'the'), 1), (('having', 'in'), 1), (('off', 'such'), 1), (('it', 'and'), 1), ((\"Nature's\", 'God'), 1), (('are', 'sufferable'), 1), (('among', 'Men'), 1), (('Happiness', 'That'), 1), (('of', 'Nature'), 1), (('institute', 'new'), 1), (('to', 'institute'), 1), (('separation', 'We'), 1), (('that', 'among'), 1), (('and', 'such'), 1), (('establishment', 'of'), 1), (('powers', 'in'), 1), (('be', 'submitted'), 1), (('former', 'Systems'), 1), (('new', 'Government'), 1), (('are', 'endowed'), 1), (('powers', 'from'), 1), (('the', 'consent'), 1), (('equal', 'station'), 1), (('the', 'forms'), 1), (('in', 'direct'), 1), (('which', 'constrains'), 1), (('security', 'Such'), 1), (('Colonies;', 'and'), 1), (('same', 'Object'), 1), (('long', 'train'), 1), (('these', 'are'), 1), (('impel', 'them'), 1), (('likely', 'to'), 1), (('dictate', 'that'), 1), (('But', 'when'), 1), (('repeated', 'injuries'), 1), (('to', 'right'), 1), (('this', 'let'), 1), (('That', 'to'), 1), (('train', 'of'), 1), (('destructive', 'of'), 1), (('Happiness', 'Prudence'), 1), (('absolute', 'Tyranny'), 1), (('Britain', 'is'), 1), (('provide', 'new'), 1), (('them', 'shall'), 1), (('the', 'governed'), 1), (('should', 'not'), 1), (('respect', 'to'), 1), (('have', 'connected'), 1), (('their', 'Safety'), 1), (('for', 'light'), 1), (('station', 'to'), 1), (('new', 'Guards'), 1), (('them', 'under'), 1), (('endowed', 'by'), 1), (('shewn', 'that'), 1), (('Such', 'has'), 1), (('injuries', 'and'), 1), (('abolishing', 'the'), 1), (('these', 'Colonies;'), 1), (('that', 'mankind'), 1), (('to', 'secure'), 1), (('the', 'pursuit'), 1), (('alter', 'or'), 1), (('has', 'been'), 1), (('accordingly', 'all'), 1), (('to', 'throw'), 1), (('Great', 'Britain'), 1), (('governed', 'That'), 1), (('among', 'these'), 1), (('of', \"Nature's\"), 1), (('and', 'organizing'), 1), (('effect', 'their'), 1), (('submitted', 'to'), 1), (('that', 'Governments'), 1), (('seem', 'most'), 1), (('People', 'to'), 1), (('and', 'Happiness'), 1), (('requires', 'that'), 1), (('ends', 'it'), 1), (('transient', 'causes;'), 1), (('throw', 'off'), 1), (('principles', 'and'), 1), (('States', 'To'), 1), (('deriving', 'their'), 1), (('Government', 'and'), 1), (('and', 'equal'), 1), (('bands', 'which'), 1), (('the', 'separation'), 1), (('powers', 'of'), 1), (('truths', 'to'), 1), (('sufferance', 'of'), 1), (('causes;', 'and'), 1), (('duty', 'to'), 1), (('themselves', 'by'), 1), (('whenever', 'any'), 1), (('should', 'declare'), 1), (('men', 'are'), 1), (('usurpations', 'pursuing'), 1), (('is', 'a'), 1), (('future', 'security'), 1), (('a', 'long'), 1), (('are', 'instituted'), 1), (('world',), 1), (('of', 'an'), 1), (('its', 'powers'), 1), (('abolish', 'it'), 1), (('candid', 'world'), 1), (('when', 'a'), 1), (('among', 'the'), 1), (('We', 'hold'), 1), (('Governments', 'long'), 1), (('evinces', 'a'), 1), (('they', 'should'), 1), (('to', 'be'), 1), (('foundation', 'on'), 1), (('its', 'foundation'), 1), (('the', 'present'), 1), (('of', 'repeated'), 1), (('is', 'now'), 1), (('prove', 'this'), 1), (('decent', 'respect'), 1), (('changed', 'for'), 1), (('the', 'patient'), 1), (('any', 'Form'), 1), (('Safety', 'and'), 1), (('their', 'future'), 1), (('mankind', 'are'), 1), (('right', 'it'), 1), (('for', 'their'), 1), (('which', 'the'), 1), (('the', 'powers'), 1), (('sufferable', 'than'), 1), (('the', 'same'), 1), (('a', 'decent'), 1), (('more', 'disposed'), 1), (('rights', 'Governments'), 1), (('Facts', 'be'), 1), (('that', 'all'), 1), (('forms', 'to'), 1), (('than', 'to'), 1), (('to', 'suffer'), 1), (('are', 'accustomed'), 1), (('To', 'prove'), 1), (('That', 'whenever'), 1), (('which', 'they'), 1), (('the', 'Right'), 1), (('of', 'Great'), 1), (('of', 'abuses'), 1), (('over', 'these'), 1), (('the', 'Laws'), 1), (('of', 'Happiness'), 1), (('the', 'earth'), 1), (('absolute', 'Despotism'), 1), (('the', 'People'), 1), (('all', 'experience'), 1), (('shall', 'seem'), 1), (('and', 'transient'), 1), (('direct', 'object'), 1)]\n"
     ]
    }
   ],
   "source": [
    "# (3) same as 2, but instead of single words, count the number of occurances of **word pairs** i.e.\n",
    "# ('bands','which'),('which','have'),...\n",
    "\n",
    "word_pair =[]\n",
    "for i in range(len(splitted_text)):\n",
    "    word_pair.append(tuple(splitted_text[i:i+2]))\n",
    "result_dict_pair = dict( [ (i, word_pair.count(i)) for i in set(word_pair) ] )\n",
    "result_dict_pair_sorted =sorted(result_dict_pair.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "print result_dict_pair_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) For the list `l =  [ 6, -5, 3, -2, 0, 8, -9, -7 ]`, return the numbers which are greater than the average (of these numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 6, 8]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l =  [ 6, -5, 3, -2, 0, 8, -9, -7 ]\n",
    "[i for i in set(l) if i>(sum(l)/len(l))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) for the tuples (2, 5, 3, 7, 10, 20, 54, 89) and (15, 16, 3, 37, 54, 21, 20, 5) return a sorted tuple that contains\n",
    "only the elements common to both the tuples (use sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 20, 54)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu1=(2, 5, 3, 7, 10, 20, 54, 89)\n",
    "tu2=(15, 16, 3, 37, 54, 21, 20, 5)\n",
    "set1=set(tu1)\n",
    "set2=set(tu2)\n",
    "com_el=list(set1&set2)\n",
    "com_el.sort()\n",
    "tuple(com_el)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) calculate the average word length for the text\n",
    "\n",
    "> TEXT =\n",
    "> On a dark desert highway, cool wind in my hair\n",
    "> Warm smell of colitas, rising up through the air\n",
    "> Up ahead in the distance, I saw a shimmering light\n",
    "> My head grew heavy and my sight grew dim\n",
    "> I had to stop for the night\n",
    "> There she stood in the doorway;\n",
    "> I heard the mission bell\n",
    "> And I was thinking to myself,\n",
    "> \"This could be Heaven or this could be Hell\"\n",
    "> Then she lit up a candle and she showed me the way\n",
    "> \n",
    "\n",
    "Average word length is the sum of all the lengths of the word tokens in the text, divided by the number of word tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length of TEXT is 3\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"\"\"\n",
    "On a dark desert highway, cool wind in my hair Warm smell of colitas, rising up through the air Up ahead in the\n",
    "distance, I saw a shimmering light My head grew heavy and my sight grew dim I had to stop for the night There she\n",
    "stood in the doorway; I heard the mission bell And I was thinking to myself, \"This could be Heaven or this could be\n",
    "Hell\" Then she lit up a candle and she showed me the way\"\"\"\n",
    "for char in '-.,\"\\n':\n",
    "    TEXT=TEXT.replace(char,' ')\n",
    "splitted_TEXT = TEXT.split()\n",
    "total_len = 0\n",
    "for i in set(splitted_TEXT):\n",
    "    total_len += len(i)\n",
    "print \"Average word length of TEXT is\", total_len/len(splitted_TEXT)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Using the same text as in the last one, remove all punctuation and output the words in sorted alphabetical order. Save this output as a CSV file with each word separated from the other by the delimiter(comma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/phesami/Desktop/DSE-UCSD/DSE/phesami/DSE200/DSE200-notebooks/data\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Desktop/DSE-UCSD/DSE/phesami/DSE200/DSE200-notebooks/data\n",
    "import csv\n",
    "TEXT = \"\"\"\n",
    "On a dark desert highway, cool wind in my hair Warm smell of colitas, rising up through the air Up ahead in the\n",
    "distance, I saw a shimmering light My head grew heavy and my sight grew dim I had to stop for the night There she\n",
    "stood in the doorway; I heard the mission bell And I was thinking to myself, \"This could be Heaven or this could be\n",
    "Hell\" Then she lit up a candle and she showed me the way\"\"\"\n",
    "for char in '-.,;\"\\ \\n':\n",
    "    TEXT=TEXT.replace(char,' ')\n",
    "\n",
    "splitted_TEXT = TEXT.split()\n",
    "for i in range(len(sorted_splitted_TEXT)):\n",
    "    splitted_TEXT[i] = splitted_TEXT[i].lower()\n",
    "    \n",
    "sorted_splitted_TEXT = sorted(splitted_TEXT)\n",
    "with open ('sorted_TEXT.csv', 'wb') as ST:\n",
    "    a=csv.writer(ST, delimiter=',')\n",
    "    a.writerows([sorted_splitted_TEXT])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) Read the text from the above separated csv file and return a dictionary of (letter:count) pair\n",
    "that counts the number of times each letter appears in that line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/phesami/Desktop/DSE-UCSD/DSE/phesami/DSE200/DSE200-notebooks/data\n",
      "{'a': 25, 'c': 6, 'b': 3, 'e': 33, 'd': 18, 'g': 10, 'f': 3, 'i': 28, 'h': 31, 'k': 2, 'm': 11, 'l': 14, 'o': 19, 'n': 18, 'p': 4, 's': 20, 'r': 15, 'u': 6, 't': 23, 'w': 10, 'v': 2, 'y': 8}\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Desktop/DSE-UCSD/DSE/phesami/DSE200/DSE200-notebooks/data\n",
    "with open ('sorted_TEXT.csv', 'r') as F:\n",
    "    lines=F.read()\n",
    "    lines=lines.strip('\\n, \\r')\n",
    "    lines=lines.replace(',','')\n",
    "    dict_letter=dict([(i,lines.count(i)) for i in set(lines)])\n",
    "    print dict_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#(9) Take as an input an array of integers, and return true if the array contains a 5 immediately after another 5 \n",
    "#somewhere.\n",
    "A=[1,5,1,6,5,3,5,2]\n",
    "B=[1,2,3,4,5,5,6,7,8,9]\n",
    "\n",
    "print consec_val(B)\n",
    "\n",
    "def consec_val(Array):\n",
    "    index_of_Fives=[i for i, val in enumerate(Array) if val==5]\n",
    "    for i in range(len(index_of_Fives)-1):\n",
    "        if (index_of_Fives[i+1]==index_of_Fives[i]+1):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10) Write  a program that takes in a positive number (in some variable, say `i`) and computes the sum of all the number\n",
    "between 0 and that number (inclusive). \n",
    "\n",
    "* Do it using a for loop\n",
    "* Do it in one line using the function `sum` and list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input a postive integer number \n",
      "100\n",
      "the sum of 0 to 100 using for loop is:  5050\n",
      "the sum of 0 to 100 using list comprehension and sum is:  5050\n"
     ]
    }
   ],
   "source": [
    "i = input('input a postive integer number \\n')\n",
    "summ =0\n",
    "for j in range(i+1):\n",
    "    summ+=j\n",
    "print \"the sum of 0 to\",i,\"using for loop is: \", summ\n",
    "\n",
    "print \"the sum of 0 to\",i,\"using list comprehension and sum is: \",sum([i for i in range(i+1)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/phesami/Desktop/DSE-UCSD/DSE/phesami/DSE200/DSE200-notebooks/data/NLTK\n",
      "the word has less than two letters\n",
      "the word has less than two letters\n",
      "the word has less than two letters\n",
      "the word has less than two letters\n",
      "the word has less than two letters\n",
      "['a', 'c', 'e', 'd', 'f', 'i', 'h', 'm', 'l', 'o', 'n', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x'] [21, 4, 27, 1, 17, 9, 42, 3, 9, 28, 26, 1, 2, 17, 22, 9, 1, 3, 3, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10a076310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(11) for the text in file BrownNews.txt (~/DSE200/data/NLTK/BrownNews.txt), \n",
    "#find the distribution of the second letter in each word. \n",
    "%cd ~/Desktop/DSE-UCSD/DSE/phesami/DSE200/DSE200-notebooks/data/NLTK\n",
    "second_letter=[] \n",
    "with open('BrownNews.txt') as BN:\n",
    "    Lines_BN=BN.read()\n",
    "    for char in '-.,;\"\\`\\' \\n':\n",
    "        Lines_BN=Lines_BN.replace(char,' ')\n",
    "    for words in Lines_BN.split():\n",
    "        try:\n",
    "            second_letter.append(words[1])\n",
    "        except:\n",
    "            print \"the word has less than two letters\"\n",
    "    \n",
    "    districbution= dict([(i,second_letter.count(i)) for i in set(second_letter)])\n",
    "print districbution.keys(), districbution.values()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "width = 0.5\n",
    "ind = np.arange(len(districbution.keys()))\n",
    "plt.bar(ind, districbution.values() , width, color='r')\n",
    "plt.xticks(ind+(width/2), districbution.keys())\n",
    "plt.ylabel('Occurance')\n",
    "plt.title('Histogram of letters used in BrownNews.txt')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12) write a program to find solutions of the 8 queen problem.\n",
    ">The eight queens problem is the problem of placing eight queens on an 8Ã—8 chessboard such that none of them attack one >another (no two are in the same row, column, or diagonal). Below is one of the arrangements of an 8 queen solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, -1, 4, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "board=[0,4,-1,-1,-1,-1,-1,-1]\n",
    "#for i in range(8):\n",
    "#    board[0]=i\n",
    "#    board[1]=\n",
    "print next_move(board)\n",
    "def next_move (board):\n",
    "    occupied_square=[]\n",
    "    for i in range(len(board)):\n",
    "        if board[i]!=-1:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    for j in range(i):\n",
    "        occupied_square.append(board[j])\n",
    "        occupied_square.append(board[j]+1)\n",
    "        occupied_square.append(board[j]-1)\n",
    "    return occupied_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4, 7, 5, 2, 6, 1, 3)\n",
      "(0, 5, 7, 2, 6, 3, 1, 4)\n",
      "(0, 6, 3, 5, 7, 1, 4, 2)\n",
      "(0, 6, 4, 7, 1, 3, 5, 2)\n",
      "(1, 3, 5, 7, 2, 0, 6, 4)\n",
      "(1, 4, 6, 0, 2, 7, 5, 3)\n",
      "(1, 4, 6, 3, 0, 7, 5, 2)\n",
      "(1, 5, 0, 6, 3, 7, 2, 4)\n",
      "(1, 5, 7, 2, 0, 3, 6, 4)\n",
      "(1, 6, 2, 5, 7, 4, 0, 3)\n",
      "(1, 6, 4, 7, 0, 3, 5, 2)\n",
      "(1, 7, 5, 0, 2, 4, 6, 3)\n",
      "(2, 0, 6, 4, 7, 1, 3, 5)\n",
      "(2, 4, 1, 7, 0, 6, 3, 5)\n",
      "(2, 4, 1, 7, 5, 3, 6, 0)\n",
      "(2, 4, 6, 0, 3, 1, 7, 5)\n",
      "(2, 4, 7, 3, 0, 6, 1, 5)\n",
      "(2, 5, 1, 4, 7, 0, 6, 3)\n",
      "(2, 5, 1, 6, 0, 3, 7, 4)\n",
      "(2, 5, 1, 6, 4, 0, 7, 3)\n",
      "(2, 5, 3, 0, 7, 4, 6, 1)\n",
      "(2, 5, 3, 1, 7, 4, 6, 0)\n",
      "(2, 5, 7, 0, 3, 6, 4, 1)\n",
      "(2, 5, 7, 0, 4, 6, 1, 3)\n",
      "(2, 5, 7, 1, 3, 0, 6, 4)\n",
      "(2, 6, 1, 7, 4, 0, 3, 5)\n",
      "(2, 6, 1, 7, 5, 3, 0, 4)\n",
      "(2, 7, 3, 6, 0, 5, 1, 4)\n",
      "(3, 0, 4, 7, 1, 6, 2, 5)\n",
      "(3, 0, 4, 7, 5, 2, 6, 1)\n",
      "(3, 1, 4, 7, 5, 0, 2, 6)\n",
      "(3, 1, 6, 2, 5, 7, 0, 4)\n",
      "(3, 1, 6, 2, 5, 7, 4, 0)\n",
      "(3, 1, 6, 4, 0, 7, 5, 2)\n",
      "(3, 1, 7, 4, 6, 0, 2, 5)\n",
      "(3, 1, 7, 5, 0, 2, 4, 6)\n",
      "(3, 5, 0, 4, 1, 7, 2, 6)\n",
      "(3, 5, 7, 1, 6, 0, 2, 4)\n",
      "(3, 5, 7, 2, 0, 6, 4, 1)\n",
      "(3, 6, 0, 7, 4, 1, 5, 2)\n",
      "(3, 6, 2, 7, 1, 4, 0, 5)\n",
      "(3, 6, 4, 1, 5, 0, 2, 7)\n",
      "(3, 6, 4, 2, 0, 5, 7, 1)\n",
      "(3, 7, 0, 2, 5, 1, 6, 4)\n",
      "(3, 7, 0, 4, 6, 1, 5, 2)\n",
      "(3, 7, 4, 2, 0, 6, 1, 5)\n",
      "(4, 0, 3, 5, 7, 1, 6, 2)\n",
      "(4, 0, 7, 3, 1, 6, 2, 5)\n",
      "(4, 0, 7, 5, 2, 6, 1, 3)\n",
      "(4, 1, 3, 5, 7, 2, 0, 6)\n",
      "(4, 1, 3, 6, 2, 7, 5, 0)\n",
      "(4, 1, 5, 0, 6, 3, 7, 2)\n",
      "(4, 1, 7, 0, 3, 6, 2, 5)\n",
      "(4, 2, 0, 5, 7, 1, 3, 6)\n",
      "(4, 2, 0, 6, 1, 7, 5, 3)\n",
      "(4, 2, 7, 3, 6, 0, 5, 1)\n",
      "(4, 6, 0, 2, 7, 5, 3, 1)\n",
      "(4, 6, 0, 3, 1, 7, 5, 2)\n",
      "(4, 6, 1, 3, 7, 0, 2, 5)\n",
      "(4, 6, 1, 5, 2, 0, 3, 7)\n",
      "(4, 6, 1, 5, 2, 0, 7, 3)\n",
      "(4, 6, 3, 0, 2, 7, 5, 1)\n",
      "(4, 7, 3, 0, 2, 5, 1, 6)\n",
      "(4, 7, 3, 0, 6, 1, 5, 2)\n",
      "(5, 0, 4, 1, 7, 2, 6, 3)\n",
      "(5, 1, 6, 0, 2, 4, 7, 3)\n",
      "(5, 1, 6, 0, 3, 7, 4, 2)\n",
      "(5, 2, 0, 6, 4, 7, 1, 3)\n",
      "(5, 2, 0, 7, 3, 1, 6, 4)\n",
      "(5, 2, 0, 7, 4, 1, 3, 6)\n",
      "(5, 2, 4, 6, 0, 3, 1, 7)\n",
      "(5, 2, 4, 7, 0, 3, 1, 6)\n",
      "(5, 2, 6, 1, 3, 7, 0, 4)\n",
      "(5, 2, 6, 1, 7, 4, 0, 3)\n",
      "(5, 2, 6, 3, 0, 7, 1, 4)\n",
      "(5, 3, 0, 4, 7, 1, 6, 2)\n",
      "(5, 3, 1, 7, 4, 6, 0, 2)\n",
      "(5, 3, 6, 0, 2, 4, 1, 7)\n",
      "(5, 3, 6, 0, 7, 1, 4, 2)\n",
      "(5, 7, 1, 3, 0, 6, 4, 2)\n",
      "(6, 0, 2, 7, 5, 3, 1, 4)\n",
      "(6, 1, 3, 0, 7, 4, 2, 5)\n",
      "(6, 1, 5, 2, 0, 3, 7, 4)\n",
      "(6, 2, 0, 5, 7, 4, 1, 3)\n",
      "(6, 2, 7, 1, 4, 0, 5, 3)\n",
      "(6, 3, 1, 4, 7, 0, 2, 5)\n",
      "(6, 3, 1, 7, 5, 0, 2, 4)\n",
      "(6, 4, 2, 0, 5, 7, 1, 3)\n",
      "(7, 1, 3, 0, 6, 4, 2, 5)\n",
      "(7, 1, 4, 2, 0, 6, 3, 5)\n",
      "(7, 2, 0, 5, 1, 4, 6, 3)\n",
      "(7, 3, 0, 2, 5, 1, 6, 4)\n",
      "Number of unique solutions are: 92\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "Num_of_queens=8\n",
    "Num_Sol = 0\n",
    "for pos_play in permutations(range(Num_of_queens)):\n",
    "    if (len(set(pos_play[i]+i for i in range(Num_of_queens)))== len(set(pos_play[i]-i for i in range(Num_of_queens)))== Num_of_queens):\n",
    "        print pos_play\n",
    "        Num_Sol+=1\n",
    "print \"Number of unique solutions are:\", Num_Sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"8queen.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(13) Write a program to make a list of all prime numbers less than 3000. A prime number can only be divided evenly by 1 and itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "11\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "Num=30\n",
    "for i in range(Num+1):\n",
    "    remainder=[]\n",
    "    remainder_trim = []\n",
    "    for j in range(i):\n",
    "        remainder.append(i%(j+1))\n",
    "        remainder_trim = remainder[1:i-1]\n",
    "    if (all(elem!=0 for elem in remainder_trim) and (i!=0) and (i!=1)):\n",
    "        print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(14) Solve the above problem using Set instead of List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "11\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "Num=30\n",
    "for i in range(Num+1):\n",
    "    remainder_set=set([])\n",
    "    for j in range(i):\n",
    "        if ((j!=0) & (j!=i-1)):\n",
    "            remainder_set.add(i%(j+1))\n",
    "    if ((all(elem!=0 for elem in remainder_set)) & (i!=0) & (i!=1)):\n",
    "         print i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
